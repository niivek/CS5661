{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 5661 Homework 1\n",
    "# Kevin Tran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Read the dataset file “Cancer.csv” (you should download it from CSNS), and store it in a Pandas DataFrame. Check out the dataset. As you see, the dataset includes 9 numerical features. The last column is the binary label (“1” means it is a malignant cancer, “0” means it is a benign tumor). You will use all 9 features in this homework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Malignant_Cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump_Thickness  Uniformity_of_Cell_Size  Uniformity_of_Cell_Shape  \\\n",
       "0                5                        1                         1   \n",
       "1                5                        4                         4   \n",
       "2                3                        1                         1   \n",
       "3                6                        8                         8   \n",
       "4                4                        1                         1   \n",
       "\n",
       "   Marginal_Adhesion  Single_Epithelial_Cell_Size  Bare_Nuclei  \\\n",
       "0                  1                            2            1   \n",
       "1                  5                            7           10   \n",
       "2                  1                            2            2   \n",
       "3                  1                            3            4   \n",
       "4                  3                            2            1   \n",
       "\n",
       "   Bland_Chromatin  Normal_Nucleoli  Mitoses  Malignant_Cancer  \n",
       "0                3                1        1                 0  \n",
       "1                3                2        1                 0  \n",
       "2                3                1        1                 0  \n",
       "3                3                7        1                 0  \n",
       "4                3                1        1                 0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cancer_df = pd.read_csv(\"Cancer_small.csv\")\n",
    "\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Use sklearn functions (see class tutorials for details) to split the dataset into testing and training sets with the following parameters: test_size=0.3, random_state=2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Clump_Thickness  Uniformity_of_Cell_Size  Uniformity_of_Cell_Shape  \\\n",
      "134                5                        8                         4   \n",
      "28                 4                        1                         1   \n",
      "65                 5                       10                         6   \n",
      "0                  5                        1                         1   \n",
      "27                 1                        1                         1   \n",
      "\n",
      "     Marginal_Adhesion  Single_Epithelial_Cell_Size  Bare_Nuclei  \\\n",
      "134                 10                            5            8   \n",
      "28                   3                            2            1   \n",
      "65                   1                           10            4   \n",
      "0                    1                            2            1   \n",
      "27                   1                            2            1   \n",
      "\n",
      "     Bland_Chromatin  Normal_Nucleoli  Mitoses  \n",
      "134                9               10        1  \n",
      "28                 3                1        1  \n",
      "65                 4               10       10  \n",
      "0                  3                1        1  \n",
      "27                 2                1        1  \n",
      "     Malignant_Cancer\n",
      "6                   0\n",
      "3                   0\n",
      "113                 1\n",
      "12                  1\n",
      "24                  1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = list(cancer_df.loc[:, cancer_df.columns != 'Malignant_Cancer'])\n",
    "label = ['Malignant_Cancer']\n",
    "\n",
    "x = cancer_df[features]\n",
    "y = cancer_df[label]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=2)\n",
    "\n",
    "print(x_train.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Use “Decision Tree Classifier” to predict Cancer based on the training/testing datasets that you built in part (b). Then, calculate and report the accuracy of your classifier. Use this command to define your tree: my_DecisionTree = DecisionTreeClassifier(random_state=2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "my_decisiontree = DecisionTreeClassifier(random_state=2)\n",
    "my_decisiontree.fit(x_train, y_train)\n",
    "y_predict_dt = my_decisiontree.predict(x_test)\n",
    "\n",
    "dec_tree_accuracy = accuracy_score(y_test, y_predict_dt)\n",
    "print(dec_tree_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.  Now, we want to perform “Bagging” based on 19 “base decision tree classifiers”. Note: you should write your own code to perform Bagging (don’t use scikit-learn functions for Bagging!) To do so, you need to perform bootstrapping first. You can write a “for” loop with loop variable i=0...18. In each iteration of the loop, you have to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - make a bootstrap sample of the original “Training” Dataset (build in part(b)) with the size of bootstarp_size = 0.8*(Size of the original dataset). You can use the following command to generate a random bootstrap dataset (“i\" is the variable of the loop, so the random_state changes in each iteration): \n",
    "### resample(X_train, n_samples = bootstarp_size , random_state=i , replace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -  Define and train a new base decision tree classifier on this dataset in each iteration:\n",
    "### Base_DecisionTree = DecisionTreeClassifier(random_state=2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -  Test “this base classifier” on the original “Testing” Dataset build in part(b), and save the prediction results for all testing samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Decision Tree Accuracy: 0.8666666666666667\n",
      "\n",
      "Sample Values: [0.7777777777777778, 0.8666666666666667, 0.8666666666666667, 0.8444444444444444, 0.8222222222222222, 0.8444444444444444, 0.8444444444444444, 0.8444444444444444, 0.8888888888888888, 0.8, 0.8444444444444444, 0.8444444444444444, 0.8444444444444444, 0.8888888888888888, 0.8222222222222222, 0.8444444444444444, 0.8444444444444444, 0.8444444444444444, 0.8666666666666667]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "n_iterations = 19\n",
    "bootstrap_size = int(len(cancer_df) * .8)\n",
    "\n",
    "bootstrap = list()\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    train = resample(x_train, n_samples=bootstrap_size , random_state=i , replace=True)\n",
    "    test = y_train.loc[train.index.values]\n",
    "\n",
    "    Base_DecisionTree = DecisionTreeClassifier(random_state=2)\n",
    "    Base_DecisionTree.fit(train, test)\n",
    "    \n",
    "    y_predict_dtc = Base_DecisionTree.predict(x_test)\n",
    "    boot_score = accuracy_score(y_test, y_predict_dtc) \n",
    "    bootstrap.append(boot_score)\n",
    "\n",
    "print('Original Decision Tree Accuracy: {}'.format(dec_tree_accuracy))\n",
    "print()\n",
    "print('Sample Values: {}'.format(bootstrap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Perform Voting to make the final decision on each data sample based on the votes of all 19 classifiers. Finally, calculate and report the accuracy of your Bagging method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niivek/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/niivek/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/niivek/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "my_vote = VotingClassifier(estimators=[('lr', clf1)])\n",
    "my_vote = my_vote.fit(x_train, y_train)\n",
    "y_predict_vote = my_vote.predict(x_test)\n",
    "\n",
    "vote_accuracy = accuracy_score(y_test, y_predict_vote)\n",
    "print(vote_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, calculate and report the accuracy of your Bagging method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.  Use scikit-learn “Adaboost” classifier to predict Cancer based on the training/testing datasets that you built in part (b). Then, calculate and report the accuracy of your classifier. Use this command to import and define your classifier: from sklearn.ensemble import AdaBoostClassifier my_AdaBoost = AdaBoostClassifier(n_estimators = 19,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niivek/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "my_AdaBoost = AdaBoostClassifier(n_estimators = 19, random_state=2)\n",
    "my_AdaBoost.fit(x_train, y_train)\n",
    "y_predict_ada = my_AdaBoost.predict(x_test)\n",
    "\n",
    "ada_boost_accuracy = accuracy_score(y_test, y_predict_ada)\n",
    "print(ada_boost_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Use scikit-learn “Random Forest” classifier to predict Cancer based on the training/testing datasets that you built in part (b). Then, calculate and report the accuracy of your classifier. Use this command to import and define your classifier: from sklearn.ensemble import RandomForestClassifier my_RandomForest = RandomForestClassifier(n_estimators = 19, bootstrap = True, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niivek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "my_RandomForest = RandomForestClassifier(n_estimators=19, bootstrap=True, random_state=2)\n",
    "my_RandomForest.fit(x_train, y_train)\n",
    "y_predict_rf = my_RandomForest.predict(x_test)\n",
    "random_forest_accuracy = accuracy_score(y_test, y_predict_rf)\n",
    "print(random_forest_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
